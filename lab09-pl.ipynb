{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2efb1385-819d-4d23-adf3-c4d6651baa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import optuna\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fd2d02a-aa86-42d4-9ce0-a3b8a1501f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "gef = np.loadtxt('GEFCOM.txt')\n",
    "cols = ['date', 'hour', 'price', 'sysload', 'zoneload', 'dotw']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f94af4-c79b-4608-9af7-8335ab2151c7",
   "metadata": {},
   "source": [
    "After loading the data, we create two forecasts - AR(1) with single estimation in two variants: jointly and separately for all hours of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa5392c7-1cc3-41b7-a80a-430cb0310e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE of Least-squares jointly:  8.37476435765813\n",
      "MAE of Least-squares separately:  8.259542237368105\n"
     ]
    }
   ],
   "source": [
    "# base cases - AR(1) model modeled jointly for all hours of the day and separately and jointly\n",
    "X = gef[:, 2:4].copy() # kopiujemy kolumny 2 i 3 z tablicy 'gef' do macierzy X\n",
    "X[:, 1] = 1 # druga kolumna macierzy X wypełniana jest wartościami 1\n",
    "X[:, 0] = np.nan # pierwsza kolumna wypełniana jest wartościami 'nan'\n",
    "X[24:, 0] = gef[:-24, 2] # the first lag of the time series is inserted into the X matrix, starting at the 24th row (do pierwszej kolumny macierzy X wstawiana jest pierwsza opóźniona wartość szeregu czasowego z tablicy 'gef', zaczynając od 24. wiersza macierzy)\n",
    "Y = gef[:, 2].copy() # the dependent variable Y is set to the second column of the gef array (zmienna zależna 'Y' jest ustawiana na drugą kolumnę tablicy 'gef')\n",
    "firstind = 24 # pierwszy indeks dla zestawu treningowego to 24\n",
    "lastind = np.argwhere(gef[:, 0] == 20130101).squeeze()[0] # searching for the first occurrence of the date 20130101 in the first column of the gef array (wyszukujemy pierwsze wystąpienie daty 20130101 w pierwszej kolumnie tablicy 'gef')\n",
    "# squeeze() method is used to convert the resulting one-dimensional array to a scalar\n",
    "Xt = X[firstind:lastind] # zmienna Xt zawiera macierz X dla zestawu treningowego\n",
    "Xf = X[lastind:] # zmienna Xf zawiera macierz X dla zestawu testowego\n",
    "Yt = Y[firstind:lastind] # zmienna Yt zawiera wektor zmiennych zależnych dla zestawu treningowego\n",
    "Yf = Y[lastind:] # zmienna Yf zawiera wektor zmiennych zależnych dla zestawu testowego\n",
    "betas = np.linalg.lstsq(Xt, Yt, rcond=None)[0] # estymacja współczynników beta dla modelu regresji liniowej z użyciem metody najmniejszych kwadratów\n",
    "betas\n",
    "forecast = np.dot(Xf, betas) # matrix multiplying the test set Xf by the estimated coefficients betas (pomnożenie macierzy testowej Xf przez estymowane współczynniki beta)\n",
    "forecast.shape == Yf.shape # sprawdzenie, czy kształt 'forecast' jest taki sam jak 'Yf'\n",
    "print('MAE of Least-squares jointly: ', np.mean(np.abs(forecast - Yf)))\n",
    "\n",
    "separate = np.zeros_like(forecast) # all elements initialized to zero, the same shape and data type as forecast (stworzenie wektora 'separate' zawierającego zera, o tym samym kształcie i typie danych co 'forecast')\n",
    "for h in range(24): # model is fit separately for each hour of the day (dopasowanie modelu AR(1) osobno dla każdej godziny w ciągu dnia)\n",
    "    betas = np.linalg.lstsq(Xt[h::24], Yt[h::24], rcond=None)[0] # wykonuje algorytm najmniejszych kwadratów na podzbiorze danych i zwraca współczynniki beta dla modelu AR(1) dla danej godziny\n",
    "    separate[h::24] = np.dot(Xf[h::24], betas) # przypisanie przewidywanych wartości np.dot(Xf[h::24], betas) do wektora separate dla każdej godziny, co odpowiada okresowi 24 godzin.\n",
    "print('MAE of Least-squares separately: ', np.mean(np.abs(separate - Yf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959bddcb-f409-424e-a209-d6e87c572d84",
   "metadata": {},
   "source": [
    "The first NN model\n",
    "------------------\n",
    "\n",
    "Recreate the joint AR(1) using a Neural Network.\n",
    "\n",
    "Note, that we are using a simple architecture, with no hidden layers. Rerun the cell below multiple times and see, that the error metric changes each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2509dd1c-5745-4a60-839b-ef0bd438d26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/75\n",
      "55/55 [==============================] - 1s 3ms/step - loss: 2073.3955 - mae: 40.6671 - val_loss: 1884.4839 - val_mae: 38.9455\n",
      "Epoch 2/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 1834.7290 - mae: 38.0883 - val_loss: 1660.0076 - val_mae: 36.4260\n",
      "Epoch 3/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 1619.5647 - mae: 35.6036 - val_loss: 1458.6019 - val_mae: 34.0013\n",
      "Epoch 4/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 1426.6498 - mae: 33.2207 - val_loss: 1277.5850 - val_mae: 31.6581\n",
      "Epoch 5/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 1254.1205 - mae: 30.9258 - val_loss: 1117.0129 - val_mae: 29.4249\n",
      "Epoch 6/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 1100.7543 - mae: 28.7385 - val_loss: 974.0617 - val_mae: 27.2817\n",
      "Epoch 7/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 965.1495 - mae: 26.6381 - val_loss: 847.5421 - val_mae: 25.2307\n",
      "Epoch 8/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 845.5629 - mae: 24.6590 - val_loss: 737.7277 - val_mae: 23.3016\n",
      "Epoch 9/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 741.3997 - mae: 22.7636 - val_loss: 640.3973 - val_mae: 21.4471\n",
      "Epoch 10/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 650.5063 - mae: 20.9811 - val_loss: 557.0844 - val_mae: 19.7218\n",
      "Epoch 11/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 572.2009 - mae: 19.3220 - val_loss: 485.1377 - val_mae: 18.1061\n",
      "Epoch 12/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 505.0829 - mae: 17.7617 - val_loss: 423.2630 - val_mae: 16.5990\n",
      "Epoch 13/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 447.8048 - mae: 16.3203 - val_loss: 371.0572 - val_mae: 15.2085\n",
      "Epoch 14/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 399.4466 - mae: 14.9882 - val_loss: 327.2105 - val_mae: 13.9285\n",
      "Epoch 15/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 358.9464 - mae: 13.7730 - val_loss: 290.3224 - val_mae: 12.7595\n",
      "Epoch 16/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 325.1653 - mae: 12.6731 - val_loss: 260.3277 - val_mae: 11.7290\n",
      "Epoch 17/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 297.5483 - mae: 11.6755 - val_loss: 234.9876 - val_mae: 10.7972\n",
      "Epoch 18/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 274.8829 - mae: 10.8071 - val_loss: 214.6500 - val_mae: 9.9955\n",
      "Epoch 19/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 256.5843 - mae: 10.0416 - val_loss: 198.2469 - val_mae: 9.2941\n",
      "Epoch 20/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 241.8341 - mae: 9.3829 - val_loss: 185.4746 - val_mae: 8.7024\n",
      "Epoch 21/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 230.2153 - mae: 8.8282 - val_loss: 175.2270 - val_mae: 8.1930\n",
      "Epoch 22/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 221.0961 - mae: 8.3473 - val_loss: 166.8973 - val_mae: 7.7506\n",
      "Epoch 23/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 213.9901 - mae: 7.9522 - val_loss: 160.6311 - val_mae: 7.3975\n",
      "Epoch 24/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 208.5987 - mae: 7.6271 - val_loss: 155.8610 - val_mae: 7.1116\n",
      "Epoch 25/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 204.4668 - mae: 7.3720 - val_loss: 152.3446 - val_mae: 6.8906\n",
      "Epoch 26/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 201.3944 - mae: 7.1619 - val_loss: 149.6273 - val_mae: 6.7110\n",
      "Epoch 27/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 199.1680 - mae: 6.9836 - val_loss: 147.5247 - val_mae: 6.5606\n",
      "Epoch 28/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 197.5039 - mae: 6.8539 - val_loss: 146.0651 - val_mae: 6.4504\n",
      "Epoch 29/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 196.3002 - mae: 6.7635 - val_loss: 145.0058 - val_mae: 6.3649\n",
      "Epoch 30/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 195.3980 - mae: 6.6916 - val_loss: 144.3485 - val_mae: 6.3098\n",
      "Epoch 31/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 194.7963 - mae: 6.6298 - val_loss: 143.6614 - val_mae: 6.2491\n",
      "Epoch 32/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 194.3107 - mae: 6.5826 - val_loss: 143.3126 - val_mae: 6.2168\n",
      "Epoch 33/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 194.0278 - mae: 6.5529 - val_loss: 143.0511 - val_mae: 6.1911\n",
      "Epoch 34/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 193.7786 - mae: 6.5238 - val_loss: 142.8120 - val_mae: 6.1660\n",
      "Epoch 35/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 193.6273 - mae: 6.5082 - val_loss: 142.6790 - val_mae: 6.1526\n",
      "Epoch 36/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 193.4853 - mae: 6.4873 - val_loss: 142.5368 - val_mae: 6.1363\n",
      "Epoch 37/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 193.4262 - mae: 6.4744 - val_loss: 142.4447 - val_mae: 6.1252\n",
      "Epoch 38/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 193.3710 - mae: 6.4605 - val_loss: 142.3830 - val_mae: 6.1187\n",
      "Epoch 39/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 193.2771 - mae: 6.4562 - val_loss: 142.3402 - val_mae: 6.1156\n",
      "Epoch 40/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 193.2285 - mae: 6.4564 - val_loss: 142.2970 - val_mae: 6.1126\n",
      "Epoch 41/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 193.1722 - mae: 6.4506 - val_loss: 142.2431 - val_mae: 6.1067\n",
      "Epoch 42/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 193.1408 - mae: 6.4422 - val_loss: 142.1901 - val_mae: 6.0997\n",
      "Epoch 43/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 193.0935 - mae: 6.4419 - val_loss: 142.1561 - val_mae: 6.0994\n",
      "Epoch 44/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 193.0363 - mae: 6.4378 - val_loss: 142.1164 - val_mae: 6.0971\n",
      "Epoch 45/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 192.9992 - mae: 6.4363 - val_loss: 142.0746 - val_mae: 6.0939\n",
      "Epoch 46/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 192.9572 - mae: 6.4335 - val_loss: 142.0338 - val_mae: 6.0915\n",
      "Epoch 47/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 192.9096 - mae: 6.4303 - val_loss: 141.9950 - val_mae: 6.0902\n",
      "Epoch 48/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 192.8692 - mae: 6.4283 - val_loss: 141.9621 - val_mae: 6.0922\n",
      "Epoch 49/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 192.8626 - mae: 6.4287 - val_loss: 141.9158 - val_mae: 6.0873\n",
      "Epoch 50/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 192.7554 - mae: 6.4338 - val_loss: 141.8911 - val_mae: 6.0944\n",
      "Epoch 51/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 192.6848 - mae: 6.4324 - val_loss: 141.8400 - val_mae: 6.0903\n",
      "Epoch 52/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 192.6977 - mae: 6.4222 - val_loss: 141.7866 - val_mae: 6.0841\n",
      "Epoch 53/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 192.5843 - mae: 6.4288 - val_loss: 141.7597 - val_mae: 6.0908\n",
      "Epoch 54/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 192.5195 - mae: 6.4287 - val_loss: 141.7009 - val_mae: 6.0850\n",
      "Epoch 55/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 192.4903 - mae: 6.4248 - val_loss: 141.6575 - val_mae: 6.0851\n",
      "Epoch 56/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 192.4184 - mae: 6.4263 - val_loss: 141.6062 - val_mae: 6.0825\n",
      "Epoch 57/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 192.3653 - mae: 6.4186 - val_loss: 141.5509 - val_mae: 6.0769\n",
      "Epoch 58/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 192.3135 - mae: 6.4179 - val_loss: 141.5070 - val_mae: 6.0788\n",
      "Epoch 59/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 192.2332 - mae: 6.4186 - val_loss: 141.4621 - val_mae: 6.0796\n",
      "Epoch 60/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 192.1712 - mae: 6.4165 - val_loss: 141.4038 - val_mae: 6.0745\n",
      "Epoch 61/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 192.0906 - mae: 6.4156 - val_loss: 141.3561 - val_mae: 6.0760\n",
      "Epoch 62/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 192.0806 - mae: 6.4217 - val_loss: 141.3056 - val_mae: 6.0761\n",
      "Epoch 63/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 191.9677 - mae: 6.4158 - val_loss: 141.2464 - val_mae: 6.0732\n",
      "Epoch 64/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 191.9225 - mae: 6.4085 - val_loss: 141.1899 - val_mae: 6.0696\n",
      "Epoch 65/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 191.8173 - mae: 6.4097 - val_loss: 141.1364 - val_mae: 6.0703\n",
      "Epoch 66/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 191.7508 - mae: 6.4106 - val_loss: 141.0851 - val_mae: 6.0711\n",
      "Epoch 67/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 191.7022 - mae: 6.4084 - val_loss: 141.0299 - val_mae: 6.0704\n",
      "Epoch 68/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 191.5940 - mae: 6.4100 - val_loss: 140.9704 - val_mae: 6.0693\n",
      "Epoch 69/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 191.5468 - mae: 6.4071 - val_loss: 140.9105 - val_mae: 6.0683\n",
      "Epoch 70/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 191.5132 - mae: 6.3994 - val_loss: 140.8420 - val_mae: 6.0625\n",
      "Epoch 71/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 191.3745 - mae: 6.4087 - val_loss: 140.7939 - val_mae: 6.0670\n",
      "Epoch 72/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 191.3559 - mae: 6.3994 - val_loss: 140.7302 - val_mae: 6.0652\n",
      "Epoch 73/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 191.2476 - mae: 6.4084 - val_loss: 140.6643 - val_mae: 6.0636\n",
      "Epoch 74/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 191.1564 - mae: 6.3956 - val_loss: 140.5889 - val_mae: 6.0577\n",
      "Epoch 75/75\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 191.0991 - mae: 6.4049 - val_loss: 140.5290 - val_mae: 6.0599\n",
      "264/264 [==============================] - 0s 493us/step\n",
      "(8424,) (8424,) (8424,)\n",
      "8.131881744750656\n",
      "Wall time: 6.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# magic command in Jupyter Notebook that allows you to time how long it takes for a particular cell to run\n",
    "# NN model for AR(1) jointly for all hours\n",
    "inputs = keras.Input(2,) # define input layer - 2 independent variables (Tworzymy warstwę wejściową naszej sieci neuronowej, która będzie przyjmować dwa wejścia.)\n",
    "# hidden = keras.layers.Dense(20, activation='relu')(inputs)\n",
    "outputs = keras.layers.Dense(1, activation='linear')(inputs) #(Tworzymy warstwę wyjściową, która składa się z jednego neuronu z liniową funkcją aktywacji. Ta warstwa będzie generować nasze przewidywania.)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs) #Tworzymy model, który składa się z warstwy wejściowej i wyjściowej\n",
    "print(model.summary())\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics='mae')\n",
    "# specifies the optimizer to use during training (Adam), the loss function to use - MSE, and the evaluation metric to use - MAE\n",
    "# Kompilujemy nasz model, definiując optymalizator, funkcję straty oraz metrykę, która będzie używana do oceny jakości modelu.\n",
    "\n",
    "#Tworzymy losową permutację indeksów danych treningowych i wyodrębniamy podzbiór treningowy oraz walidacyjny. W tym przypadku, wykorzystujemy 80% danych treningowych do uczenia modelu i 20% do walidacji.\n",
    "# set out 20% data for validation\n",
    "perm = np.random.permutation(np.arange(Xt.shape[0]))\n",
    "VAL_DATA = 0.2\n",
    "trainsubset = perm[:int((1 - VAL_DATA) * len(perm))]\n",
    "valsubset = perm[int((1 - VAL_DATA) * len(perm)):]\n",
    "\n",
    "#Trenujemy model, przekazując mu dane treningowe oraz walidacyjne. W każdej epoce model będzie aktualizował wagi, aby zminimalizować funkcję straty. Używamy metody fit(), aby dostarczyć dane treningowe, liczbę epok, dane walidacyjne oraz rozmiar partii.\n",
    "model.fit(Xt[trainsubset], Yt[trainsubset], epochs=75, validation_data=(Xt[valsubset], Yt[valsubset]), verbose=True, batch_size=256)\n",
    "# epochs parameter specifies the number of times to iterate over the entire training dataset during training\n",
    "# batch_size parameter specifies the number of samples to use for each update of the model weights\n",
    "\n",
    "#Po zakończeniu procesu uczenia, przewidujemy wyjście modelu dla danych testowych, które nie były użyte podczas treningu. Metoda predict() zwraca przewidywania dla każdego wejścia w formie tablicy Numpy. W tym przypadku, pobieramy tylko pierwszą kolumnę przewidywań i przypisujemy je do zmiennej NNpred.\n",
    "NNpred = model.predict(Xf)[:, 0] # This passes the test inputs Xf through the trained model to generate predicted outputs\n",
    "print(NNpred.shape, Yf.shape, (NNpred - Yf).shape)\n",
    "print(np.mean(np.abs(NNpred - Yf))) #MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67db7eb-0cb8-4f4c-9fba-3b6d33558567",
   "metadata": {},
   "source": [
    "The second NN model\n",
    "------------------\n",
    "\n",
    "Let us add some complexity to the model.\n",
    "\n",
    "We add two additional layers:\n",
    " - a BatchNormalization layer\n",
    " - a hidden layer\n",
    " \n",
    "The batch normalization is useful if the input data is not normalized (e.g., we forecast prices using past prices with values ranging from -100 to 300 and load forecasts with values in tens of thousands) - so it is not really helpful here.\n",
    "\n",
    "Batch normalization normalizes the activations of the previous layer at each batch, i.e., it centers and scales the inputs to have zero mean and unit variance. This helps to prevent the activations from becoming too large or too small during training, which can slow down training or lead to numerical instability.\n",
    "\n",
    "The model might perform worse than the simpler one - but that just shows that the amount of input data is too low (the NN is able to model highly complex non-linear relations in the data, but the data we pass to the NN is very scarce).\n",
    "\n",
    "hidden = keras.layers.Dense(5, activation='elu')(bn) creates a dense layer with 5 units and the 'elu' activation function. This layer takes the output from the batch normalization layer and applies a linear transformation to it, followed by the activation function. The 'elu' activation function is the Exponential Linear Unit, which is a variant of the Rectified Linear Unit (ReLU) that allows for negative values. This can help to alleviate the vanishing gradient problem, which can occur when using the ReLU activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "113aa1c7-d903-40ff-a111-8a55ccc3aadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 2)]               0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 2)                8         \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 15        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29\n",
      "Trainable params: 25\n",
      "Non-trainable params: 4\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "110/110 [==============================] - 1s 2ms/step - loss: 2629.7820 - mae: 45.6836 - val_loss: 2625.5142 - val_mae: 46.1623\n",
      "Epoch 2/30\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 2542.0198 - mae: 44.8371 - val_loss: 2491.6414 - val_mae: 44.7717\n",
      "Epoch 3/30\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 2415.2397 - mae: 43.4716 - val_loss: 2326.3093 - val_mae: 42.9599\n",
      "Epoch 4/30\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 2232.1067 - mae: 41.4419 - val_loss: 2106.7739 - val_mae: 40.4835\n",
      "Epoch 5/30\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 1992.4460 - mae: 38.7148 - val_loss: 1837.7942 - val_mae: 37.3394\n",
      "Epoch 6/30\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 1705.5291 - mae: 35.3202 - val_loss: 1533.0500 - val_mae: 33.5784\n",
      "Epoch 7/30\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 1381.6675 - mae: 31.2613 - val_loss: 1198.7988 - val_mae: 29.1764\n",
      "Epoch 8/30\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 1046.0128 - mae: 26.5640 - val_loss: 869.1613 - val_mae: 24.2236\n",
      "Epoch 9/30\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 735.6238 - mae: 21.4809 - val_loss: 593.1057 - val_mae: 19.1366\n",
      "Epoch 10/30\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 487.4286 - mae: 16.4750 - val_loss: 390.7460 - val_mae: 14.3809\n",
      "Epoch 11/30\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 333.6149 - mae: 12.3425 - val_loss: 279.7925 - val_mae: 10.8452\n",
      "Epoch 12/30\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 247.9157 - mae: 9.5144 - val_loss: 226.8098 - val_mae: 8.7097\n",
      "Epoch 13/30\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 212.7165 - mae: 8.0213 - val_loss: 205.1687 - val_mae: 7.7078\n",
      "Epoch 14/30\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 200.3117 - mae: 7.5086 - val_loss: 197.2158 - val_mae: 7.3849\n",
      "Epoch 15/30\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 194.6845 - mae: 7.3477 - val_loss: 192.5705 - val_mae: 7.2851\n",
      "Epoch 16/30\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 192.0311 - mae: 7.2821 - val_loss: 190.0419 - val_mae: 7.1903\n",
      "Epoch 17/30\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 190.0836 - mae: 7.2580 - val_loss: 188.2077 - val_mae: 7.0995\n",
      "Epoch 18/30\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 184.6830 - mae: 7.1366 - val_loss: 185.6570 - val_mae: 7.0505\n",
      "Epoch 19/30\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 184.5911 - mae: 7.1265 - val_loss: 183.3204 - val_mae: 6.9966\n",
      "Epoch 20/30\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 187.8669 - mae: 7.1526 - val_loss: 181.1367 - val_mae: 6.9507\n",
      "Epoch 21/30\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 185.7162 - mae: 7.0810 - val_loss: 179.1683 - val_mae: 6.9021\n",
      "Epoch 22/30\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 187.0559 - mae: 7.1136 - val_loss: 177.5530 - val_mae: 6.8464\n",
      "Epoch 23/30\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 179.0345 - mae: 6.9587 - val_loss: 175.6782 - val_mae: 6.8110\n",
      "Epoch 24/30\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 179.5888 - mae: 6.9827 - val_loss: 174.4231 - val_mae: 6.7465\n",
      "Epoch 25/30\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 180.6135 - mae: 6.9383 - val_loss: 172.4917 - val_mae: 6.7498\n",
      "Epoch 26/30\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 180.3610 - mae: 6.9388 - val_loss: 171.3203 - val_mae: 6.6988\n",
      "Epoch 27/30\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 174.4962 - mae: 6.8973 - val_loss: 170.5429 - val_mae: 6.6531\n",
      "Epoch 28/30\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 171.2263 - mae: 6.8659 - val_loss: 169.2796 - val_mae: 6.6524\n",
      "Epoch 29/30\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 177.3969 - mae: 6.9399 - val_loss: 168.6984 - val_mae: 6.6094\n",
      "Epoch 30/30\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 173.5674 - mae: 6.8522 - val_loss: 167.7546 - val_mae: 6.6049\n",
      "264/264 [==============================] - 0s 546us/step\n",
      "(8424,) (8424,) (8424,)\n",
      "8.33680136933286\n"
     ]
    }
   ],
   "source": [
    "# NN model for AR(1) jointly for all hours, improved\n",
    "inputs = keras.Input(2,) # define input layer - 2 independent variables\n",
    "\n",
    "bn = keras.layers.BatchNormalization()(inputs)\n",
    "\n",
    "hidden = keras.layers.Dense(5, activation='elu')(bn)\n",
    "\n",
    "outputs = keras.layers.Dense(1, activation='linear')(hidden)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "print(model.summary())\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics='mae')\n",
    "# set out 20% data for validation\n",
    "perm = np.random.permutation(np.arange(Xt.shape[0]))\n",
    "VAL_DATA = 0.2\n",
    "trainsubset = perm[:int((1 - VAL_DATA) * len(perm))]\n",
    "valsubset = perm[int((1 - VAL_DATA) * len(perm)):]\n",
    "model.fit(Xt[trainsubset], Yt[trainsubset], epochs=30, validation_data=(Xt[valsubset], Yt[valsubset]), verbose=True, batch_size=128)\n",
    "NNpred = model.predict(Xf)[:, 0]\n",
    "print(NNpred.shape, Yf.shape, (NNpred - Yf).shape)\n",
    "print(np.mean(np.abs(NNpred - Yf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744f7dba-5ec3-4211-acc0-c68d5a41b4ce",
   "metadata": {},
   "source": [
    "The multi-output model\n",
    "----------------------\n",
    "\n",
    "Now, the model will have 24 outputs, one for each hour of the day. At the same time, the number of inputs needs to grow (we need to include the information about all hours of the day).\n",
    "\n",
    "Here, the scarcity of the model might be even more visible - as we still use only a fraction of the data we have available (and the network can handle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d519277-d0bb-4e8c-a5c5-4922729077ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 25)]              0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 25)               100       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 50)                1300      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 24)                1224      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,624\n",
      "Trainable params: 2,574\n",
      "Non-trainable params: 50\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "37/37 [==============================] - 1s 4ms/step - loss: 2579.0513 - mae: 45.7141 - val_loss: 1987.5056 - val_mae: 40.0691\n",
      "Epoch 2/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2427.0684 - mae: 44.7770 - val_loss: 1328.1296 - val_mae: 32.9460\n",
      "Epoch 3/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2068.1453 - mae: 41.6178 - val_loss: 756.8497 - val_mae: 24.5802\n",
      "Epoch 4/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1574.5933 - mae: 35.9455 - val_loss: 677.5911 - val_mae: 20.9656\n",
      "Epoch 5/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1206.6206 - mae: 30.7082 - val_loss: 860.4789 - val_mae: 21.7318\n",
      "Epoch 6/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 973.5493 - mae: 27.3204 - val_loss: 869.5301 - val_mae: 22.3970\n",
      "Epoch 7/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 832.0633 - mae: 24.5742 - val_loss: 832.5132 - val_mae: 22.1996\n",
      "Epoch 8/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 728.6925 - mae: 22.7169 - val_loss: 734.6954 - val_mae: 21.2880\n",
      "Epoch 9/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 603.2469 - mae: 20.3860 - val_loss: 665.4006 - val_mae: 19.8572\n",
      "Epoch 10/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 532.7094 - mae: 18.9687 - val_loss: 539.1500 - val_mae: 18.1016\n",
      "Epoch 11/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 451.1180 - mae: 17.0511 - val_loss: 441.0333 - val_mae: 16.1164\n",
      "Epoch 12/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 356.3213 - mae: 14.7801 - val_loss: 345.8942 - val_mae: 13.9697\n",
      "Epoch 13/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 319.9702 - mae: 13.5357 - val_loss: 254.1722 - val_mae: 12.0208\n",
      "Epoch 14/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 261.0708 - mae: 11.7527 - val_loss: 193.3591 - val_mae: 10.3358\n",
      "Epoch 15/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 239.3240 - mae: 10.9533 - val_loss: 150.7225 - val_mae: 8.6947\n",
      "Epoch 16/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 231.4219 - mae: 10.0496 - val_loss: 129.0279 - val_mae: 7.8151\n",
      "Epoch 17/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 180.8112 - mae: 8.5403 - val_loss: 115.3389 - val_mae: 7.0937\n",
      "Epoch 18/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 167.7063 - mae: 8.2822 - val_loss: 102.0207 - val_mae: 6.6408\n",
      "Epoch 19/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 154.4339 - mae: 7.7457 - val_loss: 94.5600 - val_mae: 6.2816\n",
      "Epoch 20/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 151.7908 - mae: 7.5531 - val_loss: 88.1535 - val_mae: 6.0264\n",
      "Epoch 21/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 150.6496 - mae: 7.4853 - val_loss: 84.1490 - val_mae: 5.8560\n",
      "Epoch 22/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 151.9393 - mae: 7.6063 - val_loss: 83.3677 - val_mae: 5.8033\n",
      "Epoch 23/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 160.2621 - mae: 7.7631 - val_loss: 76.3330 - val_mae: 5.5204\n",
      "Epoch 24/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 158.9916 - mae: 7.1783 - val_loss: 74.2885 - val_mae: 5.4146\n",
      "Epoch 25/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 148.2119 - mae: 7.4151 - val_loss: 75.2733 - val_mae: 5.4435\n",
      "Epoch 26/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 151.8069 - mae: 7.0437 - val_loss: 67.6307 - val_mae: 5.1505\n",
      "Epoch 27/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 141.9114 - mae: 6.9608 - val_loss: 65.2966 - val_mae: 5.0474\n",
      "Epoch 28/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 156.4728 - mae: 7.1415 - val_loss: 63.2339 - val_mae: 4.9663\n",
      "Epoch 29/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 133.0832 - mae: 6.4468 - val_loss: 63.3069 - val_mae: 4.9401\n",
      "Epoch 30/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 147.0714 - mae: 6.9147 - val_loss: 62.7725 - val_mae: 4.9388\n",
      "Epoch 31/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 145.1931 - mae: 6.8439 - val_loss: 57.6644 - val_mae: 4.7329\n",
      "Epoch 32/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 126.9247 - mae: 6.4275 - val_loss: 57.4623 - val_mae: 4.7359\n",
      "Epoch 33/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 119.8895 - mae: 6.1015 - val_loss: 54.4213 - val_mae: 4.6180\n",
      "Epoch 34/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 154.6862 - mae: 6.5918 - val_loss: 55.2023 - val_mae: 4.6112\n",
      "Epoch 35/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 136.4057 - mae: 6.6875 - val_loss: 52.5261 - val_mae: 4.5403\n",
      "Epoch 36/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 146.9959 - mae: 7.0463 - val_loss: 58.3181 - val_mae: 4.7851\n",
      "Epoch 37/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 143.6715 - mae: 6.6268 - val_loss: 53.3652 - val_mae: 4.6172\n",
      "Epoch 38/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 147.9422 - mae: 6.4959 - val_loss: 47.7712 - val_mae: 4.3366\n",
      "Epoch 39/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 124.4143 - mae: 6.3461 - val_loss: 52.9829 - val_mae: 4.5967\n",
      "Epoch 40/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 130.3949 - mae: 5.9401 - val_loss: 46.1461 - val_mae: 4.2764\n",
      "Epoch 41/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 115.8213 - mae: 6.0814 - val_loss: 44.9234 - val_mae: 4.2478\n",
      "Epoch 42/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 116.2438 - mae: 6.0689 - val_loss: 43.7147 - val_mae: 4.1886\n",
      "Epoch 43/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 109.0007 - mae: 5.8880 - val_loss: 42.7968 - val_mae: 4.1599\n",
      "Epoch 44/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 111.5434 - mae: 6.0541 - val_loss: 42.4543 - val_mae: 4.1936\n",
      "Epoch 45/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 117.1899 - mae: 6.1603 - val_loss: 42.8925 - val_mae: 4.2270\n",
      "Epoch 46/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 123.0123 - mae: 5.8661 - val_loss: 40.5550 - val_mae: 4.0805\n",
      "Epoch 47/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 104.4626 - mae: 5.8621 - val_loss: 39.4878 - val_mae: 4.0348\n",
      "Epoch 48/50\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 110.2590 - mae: 6.1152 - val_loss: 40.8275 - val_mae: 4.1602\n",
      "Epoch 49/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 120.4692 - mae: 6.1089 - val_loss: 40.7827 - val_mae: 4.1672\n",
      "Epoch 50/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 107.5138 - mae: 5.9637 - val_loss: 38.8996 - val_mae: 4.0934\n",
      "11/11 [==============================] - 0s 894us/step\n",
      "(351, 24) (351, 24) (351, 24)\n",
      "8.884418009362214\n"
     ]
    }
   ],
   "source": [
    "# NN model for AR(1) with 24 outputs\n",
    "inputs = keras.Input(25,) # define input layer - 1 independent variable for 24h + ones\n",
    "bn = keras.layers.BatchNormalization()(inputs) # Apply batch normalization to the input layer\n",
    "hidden = keras.layers.Dense(50, activation='elu')(bn) # Define a hidden layer with 50 nodes and an ELU activation function\n",
    "outputs = keras.layers.Dense(24, activation='linear')(hidden) # Define the output layer with 24 nodes, corresponding to the 24 hours of the day\n",
    "model = keras.Model(inputs=inputs, outputs=outputs) #Define the NN model by specifying the input and output layers\n",
    "print(model.summary())\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics='mae')\n",
    "# Compile the NN model using the Adam optimizer, mean squared error (MSE) loss function, and mean absolute error (MAE) metric\n",
    "# set out 20% data for validation\n",
    "\n",
    "VAL_DATA = 0.2\n",
    "Xt24 = np.hstack([Xt[:, 0].reshape(len(Xt) // 24, 24), Xt[::24, 1:]])\n",
    "perm = np.random.permutation(np.arange(Xt24.shape[0])) #The training and validation subsets are then randomly selected from the reshaped training data\n",
    "Xf24 = np.hstack([Xf[:, 0].reshape(len(Xf) // 24, 24), Xf[::24, 1:]])\n",
    "Y24 = Y.reshape(len(Y) // 24, 24) #reshaped into a matrix with 24 columns\n",
    "Yf24 = Yf.reshape(len(Yf) // 24, 24)\n",
    "'''\n",
    "The difference in this code compared to the previous code is that the input \n",
    "features Xt and Xf are reshaped into a matrix with 24 columns, where each \n",
    "column represents an hour of the day. This is achieved by first selecting \n",
    "the first column of Xt (Xt[:, 0]) and reshaping it into a matrix with 24 columns \n",
    "(Xt[:, 0].reshape(len(Xt) // 24, 24)). The remaining columns of Xt are then \n",
    "concatenated to the right of this matrix (Xt[::24, 1:]) using np.hstack. \n",
    "This is done similarly for Xf.\n",
    "'''\n",
    "trainsubset = perm[:int((1 - VAL_DATA) * len(perm))]\n",
    "valsubset = perm[int((1 - VAL_DATA) * len(perm)):]\n",
    "model.fit(Xt24[trainsubset], Y24[trainsubset], epochs=50, validation_data=(Xt24[valsubset], Y24[valsubset]), verbose=True, batch_size=16)\n",
    "# Train the NN model using the training dataset and the validation dataset for 50 epochs, a batch size of 16, and verbose output\n",
    "NNpred = model.predict(Xf24)[:, :]\n",
    "# Use the trained NN model to predict the 24-hour outputs for the test dataset Xf24, and compute the mean absolute error (MAE) between the predicted outputs NNpred and the true outputs Yf24\n",
    "print(NNpred.shape, Yf24.shape, (NNpred - Yf24).shape)\n",
    "print(np.mean(np.abs(NNpred - Yf24)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb4afac-f5e4-4a1b-8588-bf8504c14ead",
   "metadata": {},
   "source": [
    "Hyper-parameter optimization\n",
    "----------------------------\n",
    "\n",
    "In the previous examples, the parameters such as number of neurons were set at some level. However, the neural networks have a lot of hyper-parameters (especially the larger ones), for example, we can even have a hyper-parameter that decides whether to include a data processing step or to include a given input variable in the model.\n",
    "\n",
    "Hyper-parameters are, by definition, parameters of the model that are not \"trained\" when training the model (the \"trainable parameters\" are the weights in the network, correponding to the beta coefficients in linear regression). We need to set the hyper-parameters prior to training the neural network, their values are typically determined in the separate optimization study.\n",
    "\n",
    "Here, we will optimize the number of neurons using optuna package. Note, that we need to set out some data to evaluate the hyper-parameter sets (and this set should be separate from the out-of-sample test that will be used to evaluate the model after choosing the hyper-parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fa77b39-d5b9-4e09-aad7-266df328e061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(670, 25) (60, 25) (670, 24) (60, 24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:32:47,544]\u001b[0m A new study created in RDB with name: study\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A new study created in RDB with name: study\n",
      "A new study created in RDB with name: study\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asia-\\anaconda3\\lib\\site-packages\\optuna\\progress_bar.py:56: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbcfb63bedb24814875375ad9023ab31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 0 finished with value: 3.4287524800830416 and parameters: {'neurons': 18, 'activation': 'relu'}. Best is trial 0 with value: 3.4287524800830416.\n",
      "Trial 0 finished with value: 3.4287524800830416 and parameters: {'neurons': 18, 'activation': 'relu'}. Best is trial 0 with value: 3.4287524800830416.\n",
      "\u001b[32m[I 2023-05-14 11:32:49,688]\u001b[0m Trial 0 finished with value: 3.4287524800830416 and parameters: {'neurons': 18, 'activation': 'relu'}. Best is trial 0 with value: 3.4287524800830416.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 1 finished with value: 5.5559230260848995 and parameters: {'neurons': 8, 'activation': 'relu'}. Best is trial 0 with value: 3.4287524800830416.\n",
      "Trial 1 finished with value: 5.5559230260848995 and parameters: {'neurons': 8, 'activation': 'relu'}. Best is trial 0 with value: 3.4287524800830416.\n",
      "\u001b[32m[I 2023-05-14 11:32:51,742]\u001b[0m Trial 1 finished with value: 5.5559230260848995 and parameters: {'neurons': 8, 'activation': 'relu'}. Best is trial 0 with value: 3.4287524800830416.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 2 finished with value: 4.440684403631422 and parameters: {'neurons': 23, 'activation': 'elu'}. Best is trial 0 with value: 3.4287524800830416.\n",
      "Trial 2 finished with value: 4.440684403631422 and parameters: {'neurons': 23, 'activation': 'elu'}. Best is trial 0 with value: 3.4287524800830416.\n",
      "\u001b[32m[I 2023-05-14 11:32:53,912]\u001b[0m Trial 2 finished with value: 4.440684403631422 and parameters: {'neurons': 23, 'activation': 'elu'}. Best is trial 0 with value: 3.4287524800830416.\u001b[0m\n",
      "WARNING:tensorflow:5 out of the last 18 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000222A5BD1940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 3 finished with value: 5.38559557363722 and parameters: {'neurons': 78, 'activation': 'sigmoid'}. Best is trial 0 with value: 3.4287524800830416.\n",
      "Trial 3 finished with value: 5.38559557363722 and parameters: {'neurons': 78, 'activation': 'sigmoid'}. Best is trial 0 with value: 3.4287524800830416.\n",
      "\u001b[32m[I 2023-05-14 11:32:56,145]\u001b[0m Trial 3 finished with value: 5.38559557363722 and parameters: {'neurons': 78, 'activation': 'sigmoid'}. Best is trial 0 with value: 3.4287524800830416.\u001b[0m\n",
      "WARNING:tensorflow:6 out of the last 20 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000222A5D748B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 4 finished with value: 5.641627480718825 and parameters: {'neurons': 45, 'activation': 'sigmoid'}. Best is trial 0 with value: 3.4287524800830416.\n",
      "Trial 4 finished with value: 5.641627480718825 and parameters: {'neurons': 45, 'activation': 'sigmoid'}. Best is trial 0 with value: 3.4287524800830416.\n",
      "\u001b[32m[I 2023-05-14 11:32:58,330]\u001b[0m Trial 4 finished with value: 5.641627480718825 and parameters: {'neurons': 45, 'activation': 'sigmoid'}. Best is trial 0 with value: 3.4287524800830416.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 5 finished with value: 3.652466649638282 and parameters: {'neurons': 67, 'activation': 'linear'}. Best is trial 0 with value: 3.4287524800830416.\n",
      "Trial 5 finished with value: 3.652466649638282 and parameters: {'neurons': 67, 'activation': 'linear'}. Best is trial 0 with value: 3.4287524800830416.\n",
      "\u001b[32m[I 2023-05-14 11:33:00,516]\u001b[0m Trial 5 finished with value: 3.652466649638282 and parameters: {'neurons': 67, 'activation': 'linear'}. Best is trial 0 with value: 3.4287524800830416.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 6 finished with value: 4.4114373228285055 and parameters: {'neurons': 38, 'activation': 'linear'}. Best is trial 0 with value: 3.4287524800830416.\n",
      "Trial 6 finished with value: 4.4114373228285055 and parameters: {'neurons': 38, 'activation': 'linear'}. Best is trial 0 with value: 3.4287524800830416.\n",
      "\u001b[32m[I 2023-05-14 11:33:02,721]\u001b[0m Trial 6 finished with value: 4.4114373228285055 and parameters: {'neurons': 38, 'activation': 'linear'}. Best is trial 0 with value: 3.4287524800830416.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 7 finished with value: 5.262202426221636 and parameters: {'neurons': 12, 'activation': 'linear'}. Best is trial 0 with value: 3.4287524800830416.\n",
      "Trial 7 finished with value: 5.262202426221636 and parameters: {'neurons': 12, 'activation': 'linear'}. Best is trial 0 with value: 3.4287524800830416.\n",
      "\u001b[32m[I 2023-05-14 11:33:04,871]\u001b[0m Trial 7 finished with value: 5.262202426221636 and parameters: {'neurons': 12, 'activation': 'linear'}. Best is trial 0 with value: 3.4287524800830416.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 8 finished with value: 5.7823882039917835 and parameters: {'neurons': 14, 'activation': 'relu'}. Best is trial 0 with value: 3.4287524800830416.\n",
      "Trial 8 finished with value: 5.7823882039917835 and parameters: {'neurons': 14, 'activation': 'relu'}. Best is trial 0 with value: 3.4287524800830416.\n",
      "\u001b[32m[I 2023-05-14 11:33:07,253]\u001b[0m Trial 8 finished with value: 5.7823882039917835 and parameters: {'neurons': 14, 'activation': 'relu'}. Best is trial 0 with value: 3.4287524800830416.\u001b[0m\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Trial 9 finished with value: 3.4130277066760595 and parameters: {'neurons': 20, 'activation': 'relu'}. Best is trial 9 with value: 3.4130277066760595.\n",
      "Trial 9 finished with value: 3.4130277066760595 and parameters: {'neurons': 20, 'activation': 'relu'}. Best is trial 9 with value: 3.4130277066760595.\n",
      "\u001b[32m[I 2023-05-14 11:33:09,467]\u001b[0m Trial 9 finished with value: 3.4130277066760595 and parameters: {'neurons': 20, 'activation': 'relu'}. Best is trial 9 with value: 3.4130277066760595.\u001b[0m\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Trial 10 finished with value: 3.2738093884785977 and parameters: {'neurons': 100, 'activation': 'elu'}. Best is trial 10 with value: 3.2738093884785977.\n",
      "Trial 10 finished with value: 3.2738093884785977 and parameters: {'neurons': 100, 'activation': 'elu'}. Best is trial 10 with value: 3.2738093884785977.\n",
      "\u001b[32m[I 2023-05-14 11:33:11,802]\u001b[0m Trial 10 finished with value: 3.2738093884785977 and parameters: {'neurons': 100, 'activation': 'elu'}. Best is trial 10 with value: 3.2738093884785977.\u001b[0m\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Trial 11 finished with value: 3.3373099912537465 and parameters: {'neurons': 93, 'activation': 'elu'}. Best is trial 10 with value: 3.2738093884785977.\n",
      "Trial 11 finished with value: 3.3373099912537465 and parameters: {'neurons': 93, 'activation': 'elu'}. Best is trial 10 with value: 3.2738093884785977.\n",
      "\u001b[32m[I 2023-05-14 11:33:14,084]\u001b[0m Trial 11 finished with value: 3.3373099912537465 and parameters: {'neurons': 93, 'activation': 'elu'}. Best is trial 10 with value: 3.2738093884785977.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 12 finished with value: 3.2198883941968286 and parameters: {'neurons': 99, 'activation': 'elu'}. Best is trial 12 with value: 3.2198883941968286.\n",
      "Trial 12 finished with value: 3.2198883941968286 and parameters: {'neurons': 99, 'activation': 'elu'}. Best is trial 12 with value: 3.2198883941968286.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:33:16,326]\u001b[0m Trial 12 finished with value: 3.2198883941968286 and parameters: {'neurons': 99, 'activation': 'elu'}. Best is trial 12 with value: 3.2198883941968286.\u001b[0m\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Trial 13 finished with value: 3.371528099801805 and parameters: {'neurons': 98, 'activation': 'elu'}. Best is trial 12 with value: 3.2198883941968286.\n",
      "Trial 13 finished with value: 3.371528099801805 and parameters: {'neurons': 98, 'activation': 'elu'}. Best is trial 12 with value: 3.2198883941968286.\n",
      "\u001b[32m[I 2023-05-14 11:33:18,566]\u001b[0m Trial 13 finished with value: 3.371528099801805 and parameters: {'neurons': 98, 'activation': 'elu'}. Best is trial 12 with value: 3.2198883941968286.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 14 finished with value: 3.5042320321400955 and parameters: {'neurons': 80, 'activation': 'elu'}. Best is trial 12 with value: 3.2198883941968286.\n",
      "Trial 14 finished with value: 3.5042320321400955 and parameters: {'neurons': 80, 'activation': 'elu'}. Best is trial 12 with value: 3.2198883941968286.\n",
      "\u001b[32m[I 2023-05-14 11:33:20,818]\u001b[0m Trial 14 finished with value: 3.5042320321400955 and parameters: {'neurons': 80, 'activation': 'elu'}. Best is trial 12 with value: 3.2198883941968286.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 15 finished with value: 4.030212674723732 and parameters: {'neurons': 62, 'activation': 'elu'}. Best is trial 12 with value: 3.2198883941968286.\n",
      "Trial 15 finished with value: 4.030212674723732 and parameters: {'neurons': 62, 'activation': 'elu'}. Best is trial 12 with value: 3.2198883941968286.\n",
      "\u001b[32m[I 2023-05-14 11:33:23,057]\u001b[0m Trial 15 finished with value: 4.030212674723732 and parameters: {'neurons': 62, 'activation': 'elu'}. Best is trial 12 with value: 3.2198883941968286.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 16 finished with value: 3.3130647282070584 and parameters: {'neurons': 88, 'activation': 'elu'}. Best is trial 12 with value: 3.2198883941968286.\n",
      "Trial 16 finished with value: 3.3130647282070584 and parameters: {'neurons': 88, 'activation': 'elu'}. Best is trial 12 with value: 3.2198883941968286.\n",
      "\u001b[32m[I 2023-05-14 11:33:25,311]\u001b[0m Trial 16 finished with value: 3.3130647282070584 and parameters: {'neurons': 88, 'activation': 'elu'}. Best is trial 12 with value: 3.2198883941968286.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 17 finished with value: 3.375118278821309 and parameters: {'neurons': 99, 'activation': 'elu'}. Best is trial 12 with value: 3.2198883941968286.\n",
      "Trial 17 finished with value: 3.375118278821309 and parameters: {'neurons': 99, 'activation': 'elu'}. Best is trial 12 with value: 3.2198883941968286.\n",
      "\u001b[32m[I 2023-05-14 11:33:27,600]\u001b[0m Trial 17 finished with value: 3.375118278821309 and parameters: {'neurons': 99, 'activation': 'elu'}. Best is trial 12 with value: 3.2198883941968286.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 18 finished with value: 3.9022050503094996 and parameters: {'neurons': 81, 'activation': 'elu'}. Best is trial 12 with value: 3.2198883941968286.\n",
      "Trial 18 finished with value: 3.9022050503094996 and parameters: {'neurons': 81, 'activation': 'elu'}. Best is trial 12 with value: 3.2198883941968286.\n",
      "\u001b[32m[I 2023-05-14 11:33:29,753]\u001b[0m Trial 18 finished with value: 3.9022050503094996 and parameters: {'neurons': 81, 'activation': 'elu'}. Best is trial 12 with value: 3.2198883941968286.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 19 finished with value: 5.378874793794421 and parameters: {'neurons': 63, 'activation': 'sigmoid'}. Best is trial 12 with value: 3.2198883941968286.\n",
      "Trial 19 finished with value: 5.378874793794421 and parameters: {'neurons': 63, 'activation': 'sigmoid'}. Best is trial 12 with value: 3.2198883941968286.\n",
      "\u001b[32m[I 2023-05-14 11:33:32,005]\u001b[0m Trial 19 finished with value: 5.378874793794421 and parameters: {'neurons': 63, 'activation': 'sigmoid'}. Best is trial 12 with value: 3.2198883941968286.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 20 finished with value: 3.5008195146984527 and parameters: {'neurons': 71, 'activation': 'elu'}. Best is trial 12 with value: 3.2198883941968286.\n",
      "Trial 20 finished with value: 3.5008195146984527 and parameters: {'neurons': 71, 'activation': 'elu'}. Best is trial 12 with value: 3.2198883941968286.\n",
      "\u001b[32m[I 2023-05-14 11:33:34,227]\u001b[0m Trial 20 finished with value: 3.5008195146984527 and parameters: {'neurons': 71, 'activation': 'elu'}. Best is trial 12 with value: 3.2198883941968286.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 21 finished with value: 3.2016165680885313 and parameters: {'neurons': 89, 'activation': 'elu'}. Best is trial 21 with value: 3.2016165680885313.\n",
      "Trial 21 finished with value: 3.2016165680885313 and parameters: {'neurons': 89, 'activation': 'elu'}. Best is trial 21 with value: 3.2016165680885313.\n",
      "\u001b[32m[I 2023-05-14 11:33:36,761]\u001b[0m Trial 21 finished with value: 3.2016165680885313 and parameters: {'neurons': 89, 'activation': 'elu'}. Best is trial 21 with value: 3.2016165680885313.\u001b[0m\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Trial 22 finished with value: 3.153422185103098 and parameters: {'neurons': 86, 'activation': 'elu'}. Best is trial 22 with value: 3.153422185103098.\n",
      "Trial 22 finished with value: 3.153422185103098 and parameters: {'neurons': 86, 'activation': 'elu'}. Best is trial 22 with value: 3.153422185103098.\n",
      "\u001b[32m[I 2023-05-14 11:33:38,948]\u001b[0m Trial 22 finished with value: 3.153422185103098 and parameters: {'neurons': 86, 'activation': 'elu'}. Best is trial 22 with value: 3.153422185103098.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 23 finished with value: 3.3033193805482646 and parameters: {'neurons': 87, 'activation': 'elu'}. Best is trial 22 with value: 3.153422185103098.\n",
      "Trial 23 finished with value: 3.3033193805482646 and parameters: {'neurons': 87, 'activation': 'elu'}. Best is trial 22 with value: 3.153422185103098.\n",
      "\u001b[32m[I 2023-05-14 11:33:41,155]\u001b[0m Trial 23 finished with value: 3.3033193805482646 and parameters: {'neurons': 87, 'activation': 'elu'}. Best is trial 22 with value: 3.153422185103098.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 24 finished with value: 3.467008167531756 and parameters: {'neurons': 88, 'activation': 'elu'}. Best is trial 22 with value: 3.153422185103098.\n",
      "Trial 24 finished with value: 3.467008167531756 and parameters: {'neurons': 88, 'activation': 'elu'}. Best is trial 22 with value: 3.153422185103098.\n",
      "\u001b[32m[I 2023-05-14 11:33:43,429]\u001b[0m Trial 24 finished with value: 3.467008167531756 and parameters: {'neurons': 88, 'activation': 'elu'}. Best is trial 22 with value: 3.153422185103098.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 25 finished with value: 4.018288916058011 and parameters: {'neurons': 54, 'activation': 'elu'}. Best is trial 22 with value: 3.153422185103098.\n",
      "Trial 25 finished with value: 4.018288916058011 and parameters: {'neurons': 54, 'activation': 'elu'}. Best is trial 22 with value: 3.153422185103098.\n",
      "\u001b[32m[I 2023-05-14 11:33:45,756]\u001b[0m Trial 25 finished with value: 4.018288916058011 and parameters: {'neurons': 54, 'activation': 'elu'}. Best is trial 22 with value: 3.153422185103098.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 26 finished with value: 3.2875026512145995 and parameters: {'neurons': 76, 'activation': 'elu'}. Best is trial 22 with value: 3.153422185103098.\n",
      "Trial 26 finished with value: 3.2875026512145995 and parameters: {'neurons': 76, 'activation': 'elu'}. Best is trial 22 with value: 3.153422185103098.\n",
      "\u001b[32m[I 2023-05-14 11:33:47,989]\u001b[0m Trial 26 finished with value: 3.2875026512145995 and parameters: {'neurons': 76, 'activation': 'elu'}. Best is trial 22 with value: 3.153422185103098.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 27 finished with value: 3.3117190238104923 and parameters: {'neurons': 90, 'activation': 'linear'}. Best is trial 22 with value: 3.153422185103098.\n",
      "Trial 27 finished with value: 3.3117190238104923 and parameters: {'neurons': 90, 'activation': 'linear'}. Best is trial 22 with value: 3.153422185103098.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:33:50,259]\u001b[0m Trial 27 finished with value: 3.3117190238104923 and parameters: {'neurons': 90, 'activation': 'linear'}. Best is trial 22 with value: 3.153422185103098.\u001b[0m\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Trial 28 finished with value: 5.414402308675978 and parameters: {'neurons': 53, 'activation': 'sigmoid'}. Best is trial 22 with value: 3.153422185103098.\n",
      "Trial 28 finished with value: 5.414402308675978 and parameters: {'neurons': 53, 'activation': 'sigmoid'}. Best is trial 22 with value: 3.153422185103098.\n",
      "\u001b[32m[I 2023-05-14 11:33:52,563]\u001b[0m Trial 28 finished with value: 5.414402308675978 and parameters: {'neurons': 53, 'activation': 'sigmoid'}. Best is trial 22 with value: 3.153422185103098.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 29 finished with value: 2.731269688182407 and parameters: {'neurons': 95, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 29 finished with value: 2.731269688182407 and parameters: {'neurons': 95, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:33:54,728]\u001b[0m Trial 29 finished with value: 2.731269688182407 and parameters: {'neurons': 95, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 30 finished with value: 2.9871035703023274 and parameters: {'neurons': 73, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 30 finished with value: 2.9871035703023274 and parameters: {'neurons': 73, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:33:56,885]\u001b[0m Trial 30 finished with value: 2.9871035703023274 and parameters: {'neurons': 73, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 31 finished with value: 3.6509461455874974 and parameters: {'neurons': 83, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 31 finished with value: 3.6509461455874974 and parameters: {'neurons': 83, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:33:59,038]\u001b[0m Trial 31 finished with value: 3.6509461455874974 and parameters: {'neurons': 83, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Trial 32 finished with value: 2.841929098394182 and parameters: {'neurons': 69, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 32 finished with value: 2.841929098394182 and parameters: {'neurons': 69, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:34:01,180]\u001b[0m Trial 32 finished with value: 2.841929098394182 and parameters: {'neurons': 69, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 33 finished with value: 3.049795692920685 and parameters: {'neurons': 72, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 33 finished with value: 3.049795692920685 and parameters: {'neurons': 72, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:34:03,342]\u001b[0m Trial 33 finished with value: 3.049795692920685 and parameters: {'neurons': 72, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 34 finished with value: 2.9995440224541556 and parameters: {'neurons': 72, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 34 finished with value: 2.9995440224541556 and parameters: {'neurons': 72, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:34:05,490]\u001b[0m Trial 34 finished with value: 2.9995440224541556 and parameters: {'neurons': 72, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 35 finished with value: 2.890622496657902 and parameters: {'neurons': 33, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 35 finished with value: 2.890622496657902 and parameters: {'neurons': 33, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:34:07,960]\u001b[0m Trial 35 finished with value: 2.890622496657902 and parameters: {'neurons': 33, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 36 finished with value: 3.1869713396496246 and parameters: {'neurons': 31, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 36 finished with value: 3.1869713396496246 and parameters: {'neurons': 31, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:34:10,095]\u001b[0m Trial 36 finished with value: 3.1869713396496246 and parameters: {'neurons': 31, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 37 finished with value: 3.028863062911564 and parameters: {'neurons': 43, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 37 finished with value: 3.028863062911564 and parameters: {'neurons': 43, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:34:12,243]\u001b[0m Trial 37 finished with value: 3.028863062911564 and parameters: {'neurons': 43, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Trial 38 finished with value: 3.0875148443116083 and parameters: {'neurons': 60, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 38 finished with value: 3.0875148443116083 and parameters: {'neurons': 60, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:34:14,408]\u001b[0m Trial 38 finished with value: 3.0875148443116083 and parameters: {'neurons': 60, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 39 finished with value: 3.001282518757714 and parameters: {'neurons': 36, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 39 finished with value: 3.001282518757714 and parameters: {'neurons': 36, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:34:16,563]\u001b[0m Trial 39 finished with value: 3.001282518757714 and parameters: {'neurons': 36, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 40 finished with value: 3.324127760251363 and parameters: {'neurons': 31, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 40 finished with value: 3.324127760251363 and parameters: {'neurons': 31, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:34:18,683]\u001b[0m Trial 40 finished with value: 3.324127760251363 and parameters: {'neurons': 31, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 41 finished with value: 3.0689789147906836 and parameters: {'neurons': 48, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 41 finished with value: 3.0689789147906836 and parameters: {'neurons': 48, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:34:20,826]\u001b[0m Trial 41 finished with value: 3.0689789147906836 and parameters: {'neurons': 48, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 42 finished with value: 3.0513679855134757 and parameters: {'neurons': 74, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 42 finished with value: 3.0513679855134757 and parameters: {'neurons': 74, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:34:22,999]\u001b[0m Trial 42 finished with value: 3.0513679855134757 and parameters: {'neurons': 74, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 43 finished with value: 2.844736504713694 and parameters: {'neurons': 57, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 43 finished with value: 2.844736504713694 and parameters: {'neurons': 57, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:34:25,160]\u001b[0m Trial 43 finished with value: 2.844736504713694 and parameters: {'neurons': 57, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 44 finished with value: 5.559378803782993 and parameters: {'neurons': 4, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 44 finished with value: 5.559378803782993 and parameters: {'neurons': 4, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:34:27,215]\u001b[0m Trial 44 finished with value: 5.559378803782993 and parameters: {'neurons': 4, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 45 finished with value: 3.085919636991289 and parameters: {'neurons': 57, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 45 finished with value: 3.085919636991289 and parameters: {'neurons': 57, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:34:29,378]\u001b[0m Trial 45 finished with value: 3.085919636991289 and parameters: {'neurons': 57, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 46 finished with value: 2.9257673135863413 and parameters: {'neurons': 66, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 46 finished with value: 2.9257673135863413 and parameters: {'neurons': 66, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:34:31,533]\u001b[0m Trial 46 finished with value: 2.9257673135863413 and parameters: {'neurons': 66, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 47 finished with value: 3.3897578394677907 and parameters: {'neurons': 68, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 47 finished with value: 3.3897578394677907 and parameters: {'neurons': 68, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:34:33,709]\u001b[0m Trial 47 finished with value: 3.3897578394677907 and parameters: {'neurons': 68, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 48 finished with value: 4.56697235472997 and parameters: {'neurons': 47, 'activation': 'linear'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 48 finished with value: 4.56697235472997 and parameters: {'neurons': 47, 'activation': 'linear'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:34:35,838]\u001b[0m Trial 48 finished with value: 4.56697235472997 and parameters: {'neurons': 47, 'activation': 'linear'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 49 finished with value: 3.4630695310168798 and parameters: {'neurons': 23, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 49 finished with value: 3.4630695310168798 and parameters: {'neurons': 23, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:34:38,357]\u001b[0m Trial 49 finished with value: 3.4630695310168798 and parameters: {'neurons': 23, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 50 finished with value: 2.954461016231113 and parameters: {'neurons': 40, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 50 finished with value: 2.954461016231113 and parameters: {'neurons': 40, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:34:40,528]\u001b[0m Trial 50 finished with value: 2.954461016231113 and parameters: {'neurons': 40, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Trial 51 finished with value: 3.170137110816108 and parameters: {'neurons': 40, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 51 finished with value: 3.170137110816108 and parameters: {'neurons': 40, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:34:42,681]\u001b[0m Trial 51 finished with value: 3.170137110816108 and parameters: {'neurons': 40, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 52 finished with value: 3.55464781973097 and parameters: {'neurons': 35, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 52 finished with value: 3.55464781973097 and parameters: {'neurons': 35, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:34:44,840]\u001b[0m Trial 52 finished with value: 3.55464781973097 and parameters: {'neurons': 35, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 53 finished with value: 3.1576007196638316 and parameters: {'neurons': 31, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 53 finished with value: 3.1576007196638316 and parameters: {'neurons': 31, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:34:46,993]\u001b[0m Trial 53 finished with value: 3.1576007196638316 and parameters: {'neurons': 31, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 54 finished with value: 5.390260978804695 and parameters: {'neurons': 66, 'activation': 'sigmoid'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 54 finished with value: 5.390260978804695 and parameters: {'neurons': 66, 'activation': 'sigmoid'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:34:49,172]\u001b[0m Trial 54 finished with value: 5.390260978804695 and parameters: {'neurons': 66, 'activation': 'sigmoid'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 55 finished with value: 2.9093656672901576 and parameters: {'neurons': 49, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 55 finished with value: 2.9093656672901576 and parameters: {'neurons': 49, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:34:51,355]\u001b[0m Trial 55 finished with value: 2.9093656672901576 and parameters: {'neurons': 49, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 56 finished with value: 3.045700789663527 and parameters: {'neurons': 57, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 56 finished with value: 3.045700789663527 and parameters: {'neurons': 57, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:34:53,593]\u001b[0m Trial 56 finished with value: 3.045700789663527 and parameters: {'neurons': 57, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 57 finished with value: 3.125917841646406 and parameters: {'neurons': 65, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 57 finished with value: 3.125917841646406 and parameters: {'neurons': 65, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:34:55,755]\u001b[0m Trial 57 finished with value: 3.125917841646406 and parameters: {'neurons': 65, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 58 finished with value: 2.804704122437371 and parameters: {'neurons': 50, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 58 finished with value: 2.804704122437371 and parameters: {'neurons': 50, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:34:57,907]\u001b[0m Trial 58 finished with value: 2.804704122437371 and parameters: {'neurons': 50, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Trial 59 finished with value: 3.741493212117089 and parameters: {'neurons': 50, 'activation': 'linear'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 59 finished with value: 3.741493212117089 and parameters: {'neurons': 50, 'activation': 'linear'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:35:00,085]\u001b[0m Trial 59 finished with value: 3.741493212117089 and parameters: {'neurons': 50, 'activation': 'linear'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 60 finished with value: 5.708182449658711 and parameters: {'neurons': 44, 'activation': 'sigmoid'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 60 finished with value: 5.708182449658711 and parameters: {'neurons': 44, 'activation': 'sigmoid'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:35:02,246]\u001b[0m Trial 60 finished with value: 5.708182449658711 and parameters: {'neurons': 44, 'activation': 'sigmoid'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 61 finished with value: 2.887868747075399 and parameters: {'neurons': 57, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 61 finished with value: 2.887868747075399 and parameters: {'neurons': 57, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:35:04,427]\u001b[0m Trial 61 finished with value: 2.887868747075399 and parameters: {'neurons': 57, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 62 finished with value: 3.3185475081867644 and parameters: {'neurons': 58, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 62 finished with value: 3.3185475081867644 and parameters: {'neurons': 58, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:35:06,895]\u001b[0m Trial 62 finished with value: 3.3185475081867644 and parameters: {'neurons': 58, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 63 finished with value: 3.109990494357215 and parameters: {'neurons': 52, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 63 finished with value: 3.109990494357215 and parameters: {'neurons': 52, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:35:09,092]\u001b[0m Trial 63 finished with value: 3.109990494357215 and parameters: {'neurons': 52, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 64 finished with value: 2.865153380023109 and parameters: {'neurons': 55, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 64 finished with value: 2.865153380023109 and parameters: {'neurons': 55, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:35:11,274]\u001b[0m Trial 64 finished with value: 2.865153380023109 and parameters: {'neurons': 55, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 65 finished with value: 2.8335142034954495 and parameters: {'neurons': 55, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 65 finished with value: 2.8335142034954495 and parameters: {'neurons': 55, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:35:13,471]\u001b[0m Trial 65 finished with value: 2.8335142034954495 and parameters: {'neurons': 55, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 66 finished with value: 2.924116523795658 and parameters: {'neurons': 61, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 66 finished with value: 2.924116523795658 and parameters: {'neurons': 61, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:35:15,642]\u001b[0m Trial 66 finished with value: 2.924116523795658 and parameters: {'neurons': 61, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 67 finished with value: 3.067539454036289 and parameters: {'neurons': 55, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 67 finished with value: 3.067539454036289 and parameters: {'neurons': 55, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:35:17,832]\u001b[0m Trial 67 finished with value: 3.067539454036289 and parameters: {'neurons': 55, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 68 finished with value: 3.1438079546822446 and parameters: {'neurons': 96, 'activation': 'linear'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 68 finished with value: 3.1438079546822446 and parameters: {'neurons': 96, 'activation': 'linear'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:35:19,994]\u001b[0m Trial 68 finished with value: 3.1438079546822446 and parameters: {'neurons': 96, 'activation': 'linear'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 69 finished with value: 2.8461957303153143 and parameters: {'neurons': 46, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 69 finished with value: 2.8461957303153143 and parameters: {'neurons': 46, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:35:22,164]\u001b[0m Trial 69 finished with value: 2.8461957303153143 and parameters: {'neurons': 46, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 70 finished with value: 5.701734443611569 and parameters: {'neurons': 44, 'activation': 'sigmoid'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 70 finished with value: 5.701734443611569 and parameters: {'neurons': 44, 'activation': 'sigmoid'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:35:24,345]\u001b[0m Trial 70 finished with value: 5.701734443611569 and parameters: {'neurons': 44, 'activation': 'sigmoid'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 71 finished with value: 2.959138360023499 and parameters: {'neurons': 51, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 71 finished with value: 2.959138360023499 and parameters: {'neurons': 51, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:35:26,524]\u001b[0m Trial 71 finished with value: 2.959138360023499 and parameters: {'neurons': 51, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 72 finished with value: 2.8909880674150257 and parameters: {'neurons': 59, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 72 finished with value: 2.8909880674150257 and parameters: {'neurons': 59, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:35:28,716]\u001b[0m Trial 72 finished with value: 2.8909880674150257 and parameters: {'neurons': 59, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Trial 73 finished with value: 3.002221124649048 and parameters: {'neurons': 55, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 73 finished with value: 3.002221124649048 and parameters: {'neurons': 55, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:35:30,887]\u001b[0m Trial 73 finished with value: 3.002221124649048 and parameters: {'neurons': 55, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 74 finished with value: 3.1464839249716863 and parameters: {'neurons': 63, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 74 finished with value: 3.1464839249716863 and parameters: {'neurons': 63, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:35:33,064]\u001b[0m Trial 74 finished with value: 3.1464839249716863 and parameters: {'neurons': 63, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 75 finished with value: 3.1569196044074164 and parameters: {'neurons': 41, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 75 finished with value: 3.1569196044074164 and parameters: {'neurons': 41, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:35:35,236]\u001b[0m Trial 75 finished with value: 3.1569196044074164 and parameters: {'neurons': 41, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 76 finished with value: 2.928962099340227 and parameters: {'neurons': 69, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 76 finished with value: 2.928962099340227 and parameters: {'neurons': 69, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:35:37,775]\u001b[0m Trial 76 finished with value: 2.928962099340227 and parameters: {'neurons': 69, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Trial 77 finished with value: 3.0111202059321935 and parameters: {'neurons': 47, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 77 finished with value: 3.0111202059321935 and parameters: {'neurons': 47, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:35:39,961]\u001b[0m Trial 77 finished with value: 3.0111202059321935 and parameters: {'neurons': 47, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Trial 78 finished with value: 2.991161678208245 and parameters: {'neurons': 53, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 78 finished with value: 2.991161678208245 and parameters: {'neurons': 53, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:35:42,147]\u001b[0m Trial 78 finished with value: 2.991161678208245 and parameters: {'neurons': 53, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 79 finished with value: 2.87795627339681 and parameters: {'neurons': 84, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 79 finished with value: 2.87795627339681 and parameters: {'neurons': 84, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:35:44,381]\u001b[0m Trial 79 finished with value: 2.87795627339681 and parameters: {'neurons': 84, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 80 finished with value: 2.967187946478526 and parameters: {'neurons': 95, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 80 finished with value: 2.967187946478526 and parameters: {'neurons': 95, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:35:46,559]\u001b[0m Trial 80 finished with value: 2.967187946478526 and parameters: {'neurons': 95, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 81 finished with value: 2.9914103705618116 and parameters: {'neurons': 79, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "Trial 81 finished with value: 2.9914103705618116 and parameters: {'neurons': 79, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\n",
      "\u001b[32m[I 2023-05-14 11:35:48,760]\u001b[0m Trial 81 finished with value: 2.9914103705618116 and parameters: {'neurons': 79, 'activation': 'relu'}. Best is trial 29 with value: 2.731269688182407.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 82 finished with value: 2.712117549154494 and parameters: {'neurons': 85, 'activation': 'relu'}. Best is trial 82 with value: 2.712117549154494.\n",
      "Trial 82 finished with value: 2.712117549154494 and parameters: {'neurons': 85, 'activation': 'relu'}. Best is trial 82 with value: 2.712117549154494.\n",
      "\u001b[32m[I 2023-05-14 11:35:50,958]\u001b[0m Trial 82 finished with value: 2.712117549154494 and parameters: {'neurons': 85, 'activation': 'relu'}. Best is trial 82 with value: 2.712117549154494.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 83 finished with value: 3.238641707579295 and parameters: {'neurons': 81, 'activation': 'relu'}. Best is trial 82 with value: 2.712117549154494.\n",
      "Trial 83 finished with value: 3.238641707579295 and parameters: {'neurons': 81, 'activation': 'relu'}. Best is trial 82 with value: 2.712117549154494.\n",
      "\u001b[32m[I 2023-05-14 11:35:53,139]\u001b[0m Trial 83 finished with value: 3.238641707579295 and parameters: {'neurons': 81, 'activation': 'relu'}. Best is trial 82 with value: 2.712117549154494.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 84 finished with value: 2.989712310314178 and parameters: {'neurons': 85, 'activation': 'relu'}. Best is trial 82 with value: 2.712117549154494.\n",
      "Trial 84 finished with value: 2.989712310314178 and parameters: {'neurons': 85, 'activation': 'relu'}. Best is trial 82 with value: 2.712117549154494.\n",
      "\u001b[32m[I 2023-05-14 11:35:55,323]\u001b[0m Trial 84 finished with value: 2.989712310314178 and parameters: {'neurons': 85, 'activation': 'relu'}. Best is trial 82 with value: 2.712117549154494.\u001b[0m\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Trial 85 finished with value: 2.8602904779116316 and parameters: {'neurons': 93, 'activation': 'relu'}. Best is trial 82 with value: 2.712117549154494.\n",
      "Trial 85 finished with value: 2.8602904779116316 and parameters: {'neurons': 93, 'activation': 'relu'}. Best is trial 82 with value: 2.712117549154494.\n",
      "\u001b[32m[I 2023-05-14 11:35:57,499]\u001b[0m Trial 85 finished with value: 2.8602904779116316 and parameters: {'neurons': 93, 'activation': 'relu'}. Best is trial 82 with value: 2.712117549154494.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 86 finished with value: 2.915352009031508 and parameters: {'neurons': 94, 'activation': 'relu'}. Best is trial 82 with value: 2.712117549154494.\n",
      "Trial 86 finished with value: 2.915352009031508 and parameters: {'neurons': 94, 'activation': 'relu'}. Best is trial 82 with value: 2.712117549154494.\n",
      "\u001b[32m[I 2023-05-14 11:35:59,676]\u001b[0m Trial 86 finished with value: 2.915352009031508 and parameters: {'neurons': 94, 'activation': 'relu'}. Best is trial 82 with value: 2.712117549154494.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 87 finished with value: 3.470242643356323 and parameters: {'neurons': 76, 'activation': 'linear'}. Best is trial 82 with value: 2.712117549154494.\n",
      "Trial 87 finished with value: 3.470242643356323 and parameters: {'neurons': 76, 'activation': 'linear'}. Best is trial 82 with value: 2.712117549154494.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:36:01,856]\u001b[0m Trial 87 finished with value: 3.470242643356323 and parameters: {'neurons': 76, 'activation': 'linear'}. Best is trial 82 with value: 2.712117549154494.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 88 finished with value: 2.876597540749444 and parameters: {'neurons': 91, 'activation': 'relu'}. Best is trial 82 with value: 2.712117549154494.\n",
      "Trial 88 finished with value: 2.876597540749444 and parameters: {'neurons': 91, 'activation': 'relu'}. Best is trial 82 with value: 2.712117549154494.\n",
      "\u001b[32m[I 2023-05-14 11:36:04,035]\u001b[0m Trial 88 finished with value: 2.876597540749444 and parameters: {'neurons': 91, 'activation': 'relu'}. Best is trial 82 with value: 2.712117549154494.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 89 finished with value: 2.9561596071985035 and parameters: {'neurons': 100, 'activation': 'relu'}. Best is trial 82 with value: 2.712117549154494.\n",
      "Trial 89 finished with value: 2.9561596071985035 and parameters: {'neurons': 100, 'activation': 'relu'}. Best is trial 82 with value: 2.712117549154494.\n",
      "\u001b[32m[I 2023-05-14 11:36:06,222]\u001b[0m Trial 89 finished with value: 2.9561596071985035 and parameters: {'neurons': 100, 'activation': 'relu'}. Best is trial 82 with value: 2.712117549154494.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 90 finished with value: 5.498974679629008 and parameters: {'neurons': 98, 'activation': 'sigmoid'}. Best is trial 82 with value: 2.712117549154494.\n",
      "Trial 90 finished with value: 5.498974679629008 and parameters: {'neurons': 98, 'activation': 'sigmoid'}. Best is trial 82 with value: 2.712117549154494.\n",
      "\u001b[32m[I 2023-05-14 11:36:08,780]\u001b[0m Trial 90 finished with value: 5.498974679629008 and parameters: {'neurons': 98, 'activation': 'sigmoid'}. Best is trial 82 with value: 2.712117549154494.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 91 finished with value: 2.829320983674791 and parameters: {'neurons': 88, 'activation': 'relu'}. Best is trial 82 with value: 2.712117549154494.\n",
      "Trial 91 finished with value: 2.829320983674791 and parameters: {'neurons': 88, 'activation': 'relu'}. Best is trial 82 with value: 2.712117549154494.\n",
      "\u001b[32m[I 2023-05-14 11:36:11,017]\u001b[0m Trial 91 finished with value: 2.829320983674791 and parameters: {'neurons': 88, 'activation': 'relu'}. Best is trial 82 with value: 2.712117549154494.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 92 finished with value: 4.124227007653978 and parameters: {'neurons': 92, 'activation': 'relu'}. Best is trial 82 with value: 2.712117549154494.\n",
      "Trial 92 finished with value: 4.124227007653978 and parameters: {'neurons': 92, 'activation': 'relu'}. Best is trial 82 with value: 2.712117549154494.\n",
      "\u001b[32m[I 2023-05-14 11:36:13,209]\u001b[0m Trial 92 finished with value: 4.124227007653978 and parameters: {'neurons': 92, 'activation': 'relu'}. Best is trial 82 with value: 2.712117549154494.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 93 finished with value: 2.958966940402984 and parameters: {'neurons': 86, 'activation': 'relu'}. Best is trial 82 with value: 2.712117549154494.\n",
      "Trial 93 finished with value: 2.958966940402984 and parameters: {'neurons': 86, 'activation': 'relu'}. Best is trial 82 with value: 2.712117549154494.\n",
      "\u001b[32m[I 2023-05-14 11:36:15,406]\u001b[0m Trial 93 finished with value: 2.958966940402984 and parameters: {'neurons': 86, 'activation': 'relu'}. Best is trial 82 with value: 2.712117549154494.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 94 finished with value: 2.7074112293985158 and parameters: {'neurons': 89, 'activation': 'relu'}. Best is trial 94 with value: 2.7074112293985158.\n",
      "Trial 94 finished with value: 2.7074112293985158 and parameters: {'neurons': 89, 'activation': 'relu'}. Best is trial 94 with value: 2.7074112293985158.\n",
      "\u001b[32m[I 2023-05-14 11:36:17,583]\u001b[0m Trial 94 finished with value: 2.7074112293985158 and parameters: {'neurons': 89, 'activation': 'relu'}. Best is trial 94 with value: 2.7074112293985158.\u001b[0m\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Trial 95 finished with value: 3.02605268907547 and parameters: {'neurons': 89, 'activation': 'relu'}. Best is trial 94 with value: 2.7074112293985158.\n",
      "Trial 95 finished with value: 3.02605268907547 and parameters: {'neurons': 89, 'activation': 'relu'}. Best is trial 94 with value: 2.7074112293985158.\n",
      "\u001b[32m[I 2023-05-14 11:36:19,753]\u001b[0m Trial 95 finished with value: 3.02605268907547 and parameters: {'neurons': 89, 'activation': 'relu'}. Best is trial 94 with value: 2.7074112293985158.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 96 finished with value: 2.865388069841597 and parameters: {'neurons': 82, 'activation': 'relu'}. Best is trial 94 with value: 2.7074112293985158.\n",
      "Trial 96 finished with value: 2.865388069841597 and parameters: {'neurons': 82, 'activation': 'relu'}. Best is trial 94 with value: 2.7074112293985158.\n",
      "\u001b[32m[I 2023-05-14 11:36:21,922]\u001b[0m Trial 96 finished with value: 2.865388069841597 and parameters: {'neurons': 82, 'activation': 'relu'}. Best is trial 94 with value: 2.7074112293985158.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 97 finished with value: 2.854081439601051 and parameters: {'neurons': 96, 'activation': 'relu'}. Best is trial 94 with value: 2.7074112293985158.\n",
      "Trial 97 finished with value: 2.854081439601051 and parameters: {'neurons': 96, 'activation': 'relu'}. Best is trial 94 with value: 2.7074112293985158.\n",
      "\u001b[32m[I 2023-05-14 11:36:24,091]\u001b[0m Trial 97 finished with value: 2.854081439601051 and parameters: {'neurons': 96, 'activation': 'relu'}. Best is trial 94 with value: 2.7074112293985158.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 98 finished with value: 3.235945754316118 and parameters: {'neurons': 96, 'activation': 'relu'}. Best is trial 94 with value: 2.7074112293985158.\n",
      "Trial 98 finished with value: 3.235945754316118 and parameters: {'neurons': 96, 'activation': 'relu'}. Best is trial 94 with value: 2.7074112293985158.\n",
      "\u001b[32m[I 2023-05-14 11:36:26,245]\u001b[0m Trial 98 finished with value: 3.235945754316118 and parameters: {'neurons': 96, 'activation': 'relu'}. Best is trial 94 with value: 2.7074112293985158.\u001b[0m\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Trial 99 finished with value: 3.105932550695208 and parameters: {'neurons': 87, 'activation': 'relu'}. Best is trial 94 with value: 2.7074112293985158.\n",
      "Trial 99 finished with value: 3.105932550695208 and parameters: {'neurons': 87, 'activation': 'relu'}. Best is trial 94 with value: 2.7074112293985158.\n",
      "\u001b[32m[I 2023-05-14 11:36:28,411]\u001b[0m Trial 99 finished with value: 3.105932550695208 and parameters: {'neurons': 87, 'activation': 'relu'}. Best is trial 94 with value: 2.7074112293985158.\u001b[0m\n",
      "{'activation': 'relu', 'neurons': 89}\n",
      "Model: \"model_103\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_104 (InputLayer)      [(None, 25)]              0         \n",
      "                                                                 \n",
      " batch_normalization_102 (Ba  (None, 25)               100       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_205 (Dense)           (None, 89)                2314      \n",
      "                                                                 \n",
      " dense_206 (Dense)           (None, 24)                2160      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,574\n",
      "Trainable params: 4,524\n",
      "Non-trainable params: 50\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "37/37 [==============================] - 1s 4ms/step - loss: 2615.7085 - mae: 45.6489 - val_loss: 1744.1615 - val_mae: 37.7977\n",
      "Epoch 2/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2330.8447 - mae: 42.8445 - val_loss: 1050.1846 - val_mae: 29.1561\n",
      "Epoch 3/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1728.4137 - mae: 36.0610 - val_loss: 540.6434 - val_mae: 19.8566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1085.4238 - mae: 27.0637 - val_loss: 542.1802 - val_mae: 17.4319\n",
      "Epoch 5/50\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 806.3093 - mae: 23.0279 - val_loss: 598.0780 - val_mae: 18.1544\n",
      "Epoch 6/50\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 733.5028 - mae: 22.0397 - val_loss: 606.3066 - val_mae: 19.2911\n",
      "Epoch 7/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 681.2515 - mae: 21.2640 - val_loss: 594.0110 - val_mae: 20.2481\n",
      "Epoch 8/50\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 636.6631 - mae: 20.6546 - val_loss: 567.9300 - val_mae: 20.0803\n",
      "Epoch 9/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 559.4611 - mae: 19.2462 - val_loss: 513.9195 - val_mae: 18.9958\n",
      "Epoch 10/50\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 521.2545 - mae: 18.6638 - val_loss: 431.9059 - val_mae: 17.5341\n",
      "Epoch 11/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 414.7788 - mae: 16.3691 - val_loss: 328.6089 - val_mae: 15.1811\n",
      "Epoch 12/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 336.0438 - mae: 14.2095 - val_loss: 224.5100 - val_mae: 12.1577\n",
      "Epoch 13/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 241.3944 - mae: 11.4521 - val_loss: 146.2126 - val_mae: 9.3335\n",
      "Epoch 14/50\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 185.3057 - mae: 9.4978 - val_loss: 96.3131 - val_mae: 6.8194\n",
      "Epoch 15/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 164.7762 - mae: 8.4610 - val_loss: 71.8583 - val_mae: 5.9536\n",
      "Epoch 16/50\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 164.5717 - mae: 7.7936 - val_loss: 56.7044 - val_mae: 5.0499\n",
      "Epoch 17/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 134.3660 - mae: 7.0338 - val_loss: 52.5038 - val_mae: 5.1064\n",
      "Epoch 18/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 136.5934 - mae: 6.8728 - val_loss: 45.6646 - val_mae: 4.5852\n",
      "Epoch 19/50\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 125.5267 - mae: 6.5154 - val_loss: 43.9207 - val_mae: 4.6163\n",
      "Epoch 20/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 127.1674 - mae: 6.6728 - val_loss: 40.6682 - val_mae: 4.4088\n",
      "Epoch 21/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 113.2000 - mae: 6.2910 - val_loss: 38.1687 - val_mae: 4.1424\n",
      "Epoch 22/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 136.6443 - mae: 6.6396 - val_loss: 36.6718 - val_mae: 4.1878\n",
      "Epoch 23/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 121.7381 - mae: 6.1573 - val_loss: 36.0819 - val_mae: 4.1652\n",
      "Epoch 24/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 126.4290 - mae: 6.4251 - val_loss: 34.9886 - val_mae: 3.9988\n",
      "Epoch 25/50\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 129.5877 - mae: 6.4606 - val_loss: 34.0966 - val_mae: 4.0130\n",
      "Epoch 26/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 118.9085 - mae: 6.2276 - val_loss: 33.9047 - val_mae: 4.1070\n",
      "Epoch 27/50\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 126.0566 - mae: 6.4256 - val_loss: 32.3151 - val_mae: 3.9062\n",
      "Epoch 28/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 134.7380 - mae: 6.6750 - val_loss: 32.4367 - val_mae: 3.9100\n",
      "Epoch 29/50\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 111.7604 - mae: 6.1802 - val_loss: 31.8293 - val_mae: 3.8666\n",
      "Epoch 30/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 123.1602 - mae: 6.1477 - val_loss: 30.3672 - val_mae: 3.7888\n",
      "Epoch 31/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 116.4058 - mae: 6.0788 - val_loss: 30.4037 - val_mae: 3.7740\n",
      "Epoch 32/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 103.0152 - mae: 6.0134 - val_loss: 31.3042 - val_mae: 3.9413\n",
      "Epoch 33/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 95.8310 - mae: 5.6257 - val_loss: 29.6128 - val_mae: 3.7544\n",
      "Epoch 34/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 125.7455 - mae: 6.2320 - val_loss: 30.0589 - val_mae: 3.8188\n",
      "Epoch 35/50\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 116.1971 - mae: 6.0404 - val_loss: 29.7916 - val_mae: 3.8326\n",
      "Epoch 36/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 113.9935 - mae: 6.2413 - val_loss: 29.1719 - val_mae: 3.7339\n",
      "Epoch 37/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 118.3024 - mae: 6.2777 - val_loss: 29.2648 - val_mae: 3.7209\n",
      "Epoch 38/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 113.1685 - mae: 6.4909 - val_loss: 28.7818 - val_mae: 3.6641\n",
      "Epoch 39/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 97.9824 - mae: 5.5909 - val_loss: 28.6913 - val_mae: 3.6556\n",
      "Epoch 40/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 102.8456 - mae: 6.0125 - val_loss: 28.7788 - val_mae: 3.6441\n",
      "Epoch 41/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 102.8140 - mae: 5.8091 - val_loss: 28.5769 - val_mae: 3.6747\n",
      "Epoch 42/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 106.4829 - mae: 5.9081 - val_loss: 27.8670 - val_mae: 3.6078\n",
      "Epoch 43/50\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 117.9557 - mae: 6.3241 - val_loss: 27.3842 - val_mae: 3.5810\n",
      "Epoch 44/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 124.5923 - mae: 6.5902 - val_loss: 27.6958 - val_mae: 3.5527\n",
      "Epoch 45/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 105.3079 - mae: 5.9107 - val_loss: 28.1800 - val_mae: 3.6145\n",
      "Epoch 46/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 104.2413 - mae: 5.9947 - val_loss: 28.7364 - val_mae: 3.7401\n",
      "Epoch 47/50\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 109.0109 - mae: 5.9477 - val_loss: 28.1910 - val_mae: 3.4665\n",
      "Epoch 48/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 99.7638 - mae: 5.8131 - val_loss: 27.1208 - val_mae: 3.5399\n",
      "Epoch 49/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 105.5133 - mae: 5.9462 - val_loss: 28.2973 - val_mae: 3.4934\n",
      "Epoch 50/50\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 107.5373 - mae: 5.8327 - val_loss: 27.9403 - val_mae: 3.5228\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "(351, 24) (351, 24) (351, 24)\n",
      "9.599033600815343\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import logging\n",
    "import sys\n",
    "Xt24 = np.hstack([Xt[:, 0].reshape(len(Xt) // 24, 24), Xt[::24, 1:]])\n",
    "Xf24 = np.hstack([Xf[:, 0].reshape(len(Xf) // 24, 24), Xf[::24, 1:]])\n",
    "Y24 = Y.reshape(len(Y) // 24, 24)\n",
    "Y24 = Y24[:len(Xt24)]\n",
    "Yf24 = Yf.reshape(len(Yf) // 24, 24)\n",
    "\n",
    "# hyper-parameter optimization step\n",
    "# we will use the part of the training data - with the last 60 days being left out for the evaluation\n",
    "Xt_opti = Xt24[:-60]\n",
    "Xf_opti = Xt24[-60:]\n",
    "Yt_opti = Y24[:-60]\n",
    "Yf_opti = Y24[-60:]\n",
    "print(Xt_opti.shape, Xf_opti.shape, Yt_opti.shape, Yf_opti.shape)\n",
    "\n",
    "def objective(trial):\n",
    "    # function for the hyper-parameter optimization of the neural network model. The function takes in a trial object from the Optuna \n",
    "    #library, which contains the parameters being optimized. The function defines a neural network with one hidden layer and the number \n",
    "    #of hidden neurons and the activation function of the hidden layer are optimized. The function returns the mean absolute error between \n",
    "    #the predicted and actual values on the validation set.\n",
    "    \n",
    "    # Build a NN that has one hidden layer and optimize the number of hiden neurons and the hidden activation\n",
    "    neurons = trial.suggest_int('neurons', 3, 100) #samples integer values from a uniform distribution in the range between 3 and 100\n",
    "    activation = trial.suggest_categorical('activation', ['elu', 'relu', 'linear', 'sigmoid']) #samples the activation function from a set of categorical choices\n",
    "    # the rest of the parameters will be fixed\n",
    "    inputs = keras.Input(25,) # define input layer - 1 independent variable for 24h + ones\n",
    "    bn = keras.layers.BatchNormalization()(inputs)\n",
    "    hidden = keras.layers.Dense(neurons, activation=activation)(bn)\n",
    "    outputs = keras.layers.Dense(24, activation='linear')(hidden)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics='mae')\n",
    "    # note we don't have the validation here - this is only to simplify, it can and should be used\n",
    "    model.fit(Xt_opti, Yt_opti, epochs=50, verbose=False, batch_size=16)\n",
    "    NNpred = model.predict(Xf_opti)[:, :]\n",
    "    return np.mean(np.abs(NNpred - Yf_opti))\n",
    "\n",
    "optuna.logging.get_logger('optuna').addHandler(logging.StreamHandler(sys.stdout)) # sets up logging to output the results of the optimization to the console\n",
    "study_name = 'study'\n",
    "storage_name = 'sqlite:///study.sqlite'\n",
    "storage = optuna.storages.RDBStorage(url=storage_name)\n",
    "study_id = storage.get_study_id_from_name(study_name)\n",
    "if study_id is not None:\n",
    "    storage.delete_study(study_id)\n",
    "\n",
    "study = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=False) # creates a new study object with the specified name and database storage location\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=True) # runs the optimization process on the defined objective function, with 100 trials to search the hyperparameter space and a progress bar to display the status of the optimization\n",
    "\n",
    "best_params = study.best_params #  retrieves the best set of hyperparameters found by the optimization process\n",
    "print(best_params)\n",
    "\n",
    "# NN model for AR(1) with 24 outputs with hyper-parameter optimization -- using the optimized parameters\n",
    "inputs = keras.Input(25,) # define input layer - 1 independent variable for 24h + ones\n",
    "bn = keras.layers.BatchNormalization()(inputs)\n",
    "hidden = keras.layers.Dense(best_params['neurons'], activation=best_params['activation'])(bn)\n",
    "outputs = keras.layers.Dense(24, activation='linear')(hidden)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "print(model.summary())\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics='mae')\n",
    "# set out 20% data for validation\n",
    "\n",
    "VAL_DATA = 0.2\n",
    "perm = np.random.permutation(np.arange(Xt24.shape[0]))\n",
    "\n",
    "trainsubset = perm[:int((1 - VAL_DATA) * len(perm))]\n",
    "valsubset = perm[int((1 - VAL_DATA) * len(perm)):]\n",
    "model.fit(Xt24[trainsubset], Y24[trainsubset], epochs=50, validation_data=(Xt24[valsubset], Y24[valsubset]), verbose=True, batch_size=16)\n",
    "NNpred = model.predict(Xf24)[:, :]\n",
    "print(NNpred.shape, Yf24.shape, (NNpred - Yf24).shape)\n",
    "print(np.mean(np.abs(NNpred - Yf24)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c1b0369-4b91-4545-8280-249167a953f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.599033600815343\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(np.abs(NNpred - Yf24)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef20efd2-8a28-4f55-9002-2eaa7482b11d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu', 'neurons': 89}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17fcf952-2662-4e7b-9992-d4225dc28a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_activation</th>\n",
       "      <th>params_neurons</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.174398</td>\n",
       "      <td>2023-05-10 16:20:59.149699</td>\n",
       "      <td>2023-05-10 16:21:04.908337</td>\n",
       "      <td>0 days 00:00:05.758638</td>\n",
       "      <td>relu</td>\n",
       "      <td>51</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.852951</td>\n",
       "      <td>2023-05-10 16:21:05.009577</td>\n",
       "      <td>2023-05-10 16:21:10.817795</td>\n",
       "      <td>0 days 00:00:05.808218</td>\n",
       "      <td>linear</td>\n",
       "      <td>12</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.206507</td>\n",
       "      <td>2023-05-10 16:21:10.943480</td>\n",
       "      <td>2023-05-10 16:21:15.280943</td>\n",
       "      <td>0 days 00:00:04.337463</td>\n",
       "      <td>relu</td>\n",
       "      <td>92</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.118102</td>\n",
       "      <td>2023-05-10 16:21:15.357263</td>\n",
       "      <td>2023-05-10 16:21:22.269394</td>\n",
       "      <td>0 days 00:00:06.912131</td>\n",
       "      <td>relu</td>\n",
       "      <td>35</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.917021</td>\n",
       "      <td>2023-05-10 16:21:22.369381</td>\n",
       "      <td>2023-05-10 16:21:28.245127</td>\n",
       "      <td>0 days 00:00:05.875746</td>\n",
       "      <td>relu</td>\n",
       "      <td>8</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>2.853811</td>\n",
       "      <td>2023-05-10 16:28:33.177632</td>\n",
       "      <td>2023-05-10 16:28:38.622553</td>\n",
       "      <td>0 days 00:00:05.444921</td>\n",
       "      <td>relu</td>\n",
       "      <td>82</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>3.012801</td>\n",
       "      <td>2023-05-10 16:28:38.739638</td>\n",
       "      <td>2023-05-10 16:28:44.558821</td>\n",
       "      <td>0 days 00:00:05.819183</td>\n",
       "      <td>relu</td>\n",
       "      <td>57</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>3.031410</td>\n",
       "      <td>2023-05-10 16:28:44.646746</td>\n",
       "      <td>2023-05-10 16:28:49.979856</td>\n",
       "      <td>0 days 00:00:05.333110</td>\n",
       "      <td>linear</td>\n",
       "      <td>87</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>3.005826</td>\n",
       "      <td>2023-05-10 16:28:50.066853</td>\n",
       "      <td>2023-05-10 16:28:55.117593</td>\n",
       "      <td>0 days 00:00:05.050740</td>\n",
       "      <td>relu</td>\n",
       "      <td>94</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>5.383955</td>\n",
       "      <td>2023-05-10 16:28:55.204335</td>\n",
       "      <td>2023-05-10 16:29:01.117522</td>\n",
       "      <td>0 days 00:00:05.913187</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>78</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    number     value             datetime_start          datetime_complete  \\\n",
       "0        0  3.174398 2023-05-10 16:20:59.149699 2023-05-10 16:21:04.908337   \n",
       "1        1  5.852951 2023-05-10 16:21:05.009577 2023-05-10 16:21:10.817795   \n",
       "2        2  3.206507 2023-05-10 16:21:10.943480 2023-05-10 16:21:15.280943   \n",
       "3        3  3.118102 2023-05-10 16:21:15.357263 2023-05-10 16:21:22.269394   \n",
       "4        4  4.917021 2023-05-10 16:21:22.369381 2023-05-10 16:21:28.245127   \n",
       "..     ...       ...                        ...                        ...   \n",
       "95      95  2.853811 2023-05-10 16:28:33.177632 2023-05-10 16:28:38.622553   \n",
       "96      96  3.012801 2023-05-10 16:28:38.739638 2023-05-10 16:28:44.558821   \n",
       "97      97  3.031410 2023-05-10 16:28:44.646746 2023-05-10 16:28:49.979856   \n",
       "98      98  3.005826 2023-05-10 16:28:50.066853 2023-05-10 16:28:55.117593   \n",
       "99      99  5.383955 2023-05-10 16:28:55.204335 2023-05-10 16:29:01.117522   \n",
       "\n",
       "                 duration params_activation  params_neurons     state  \n",
       "0  0 days 00:00:05.758638              relu              51  COMPLETE  \n",
       "1  0 days 00:00:05.808218            linear              12  COMPLETE  \n",
       "2  0 days 00:00:04.337463              relu              92  COMPLETE  \n",
       "3  0 days 00:00:06.912131              relu              35  COMPLETE  \n",
       "4  0 days 00:00:05.875746              relu               8  COMPLETE  \n",
       "..                    ...               ...             ...       ...  \n",
       "95 0 days 00:00:05.444921              relu              82  COMPLETE  \n",
       "96 0 days 00:00:05.819183              relu              57  COMPLETE  \n",
       "97 0 days 00:00:05.333110            linear              87  COMPLETE  \n",
       "98 0 days 00:00:05.050740              relu              94  COMPLETE  \n",
       "99 0 days 00:00:05.913187           sigmoid              78  COMPLETE  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.trials_dataframe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
